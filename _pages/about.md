---
permalink: /
title: "About"
excerpt: "About"
# header:
#   overlay_image: /assets/images/positional_embedding.png

author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!---I am an incoming Ph.D. student at the University of Wisconsin-Madison. Previously, -->
<!-- I obtained a Master of Science in Computer Science at the University of Southern California (USC). Before that, I received my bachelor’s Degree at Sun Yat-sen University (SYSU).

My research lies in Computer Vision and Machine Learning. I am particularly interested in Vision-Languauage learning, Learning with Less Labeling.   -->
<!-- <p>I am a first-year Ph.D. student in the Department of Computer Science, University of Wisconsin-Madison, advised by Professor Yin Li</p>
<p>I obtained a Master of Science in Computer Science at the University of Southern California (USC), advised by Professor Ram Nevatia. Before that, I received my bachelor’s degree at Sun Yat-sen University (SYSU).</p>
<p style="margin-bottom: 2em;">My research lies in Computer Vision and Machine Learning. I am particularly interested in Vision-Languauage learning, Learning with Less Labeling. </p> -->


I am a third-year Ph.D. student in the Department of Computer Science, University of Wisconsin-Madison, advised by Professor [Yin Li](https://scholar.google.com/citations?hl=en&user=_y-8nrcAAAAJ&view_op=list_works&sortby=pubdate).

I obtained a Master of Science in Computer Science at the University of Southern California, advised by Professor [Ram Nevatia](https://sites.usc.edu/iris-cvlab/professor-ram-nevatia/). Before that, I received my bachelor’s degree at Sun Yat-sen University.

My research lies in Computer Vision and Machine Learning. I am particularly interested in Vision-Languauage Learning, Video Understanding. 


<!-- <h1 style="margin-bottom: 0.2em;">News</h1>
<div style="display: flex; flex-direction: row; align-items: center;">
  <img src="https://dragonlzm.github.io/zhuomingliu.github.io/images/EZSD.png" style="width: 30%; margin-right: 20px;">
  <div>
    <h2><a href="https://arxiv.org/abs/2303.12145" style="font-size: 18px;">Zero-Shot Detection via Image-Language Knowledge Distillation on Weakly Supervised Regions</a></h2>
    <p style="margin-bottom: 0.2em; font-size: 15px;">ArXiv Preprint 2023.</p>
    <p style="font-size: 15px;">Zhuoming Liu*, Xuefeng Hu*, Ram Nevatia</p>
  </div>
</div> -->

<!--  -->
<!-- <h1>Updates</h1>
<div style="display: flex; flex-direction: row; align-items: center; margin-bottom: 2em;"> 
    <img src="https://dragonlzm.github.io/zhuomingliu.github.io/images/EZSD.png" style="width: 30%; margin-right: 20px;" />
    <div>
        <h2> Efficient Feature Distillation for Zero-shot Annotation Object Detection </h2>
        <p style="font-size: 15px; margin-bottom: -0.2em">IEEE/CVF Winter Conference on Applications of Computer Vision 2024 (WACV 2024).</p>
        <p style="font-size: 15px; margin-bottom: -0.2em">Zhuoming Liu*, Xuefeng Hu*, Ram Nevatia</p>
        <p style="font-size: 15px; "> <a href="https://arxiv.org/abs/2303.12145">Paper</a> | <a href="https://github.com/dragonlzm/EZAD/">Code</a> </p>
    </div>
</div> -->

---

<h1 style=" margin-top: 2em; margin-bottom: -0.5em;">Updates</h1>
<div style="display: flex; flex-direction: row; align-items: center; margin-top: 5px; margin-bottom: 1em;">
    <img src="https://dragonlzm.github.io/zhuomingliu.github.io/images/PAVE.png" style="width: 36%; margin-right: 20px;" />
    <div>
        <h2>PAVE: Patching and Adapting Video Large Language Models</h2>
        <p style="font-size: 15px; margin-bottom: -0.05em;">The IEEE/CVF Conference on Computer Vision and Pattern Recognition 2025 (CVPR 2025).</p>
        <p style="font-size: 15px; margin-bottom: -0.05em;">Zhuoming Liu, Yiquan Li, Khoi Duc Nguyen, Yiwu Zhong, Yin Li</p>
        <p style="font-size: 15px; "><a href="https://arxiv.org/abs/2503.19794">Paper</a> | <a href="https://github.com/dragonlzm/PAVE">Code</a></p>
    </div>
</div>

<div style="display: flex; flex-direction: row; align-items: center; margin-top: 10px; margin-bottom: 1em;">
    <img src="https://dragonlzm.github.io/zhuomingliu.github.io/images/AIM.png" style="width: 36%; margin-right: 20px;" />
    <div>
        <h2>AIM: Adaptive Inference of Multi-Modal LLMs via Token Merging and Pruning</h2>
        <p style="font-size: 15px; margin-bottom: -0.05em;">The IEEE/CVF International Conference on Computer Vision 2025 (ICCV 2025).</p>
        <p style="font-size: 15px; margin-bottom: -0.05em;">Yiwu Zhong, Zhuoming Liu, Yin Li, Liwei Wang</p>
        <p style="font-size: 15px; "><a href="https://huggingface.co/papers/2412.03248">Paper</a> | <a href=" https://github.com/LaVi-Lab/AIM">Code</a> </p>
    </div>
</div>

<div style="display: flex; flex-direction: row; align-items: center; margin-top: 5px; margin-bottom: 1em;">
    <img src="https://dragonlzm.github.io/zhuomingliu.github.io/images/agile3d_copy.png" style="width: 36%; margin-right: 20px;" />
    <div>
        <h2>Agile3D: Adaptive Contention- and Content-Aware 3D Object Detection for Embedded GPUs</h2>
        <p style="font-size: 15px; margin-bottom: -0.05em;">The 23rd ACM International Conference on Mobile Systems, Applications, and Services (MobiSys 2025).</p>
        <p style="font-size: 15px; margin-bottom: -0.05em;">Pengcheng Wang, Zhuoming Liu, Shayok Bagchi, Ran Xu, Saurabh Bagchi, Yin Li, Somali Chaterji</p>
        <p style="font-size: 15px; "><a href="https://dl.acm.org/doi/10.1145/3711875.3729147">Paper</a> | <a href="https://github.com/ChulanZhang/Agile3D">Code</a></p>
    </div>
</div>



<!-- <div style="display: flex; flex-direction: row; align-items: center; margin-top: 10px; margin-bottom: 1em;">
    <img src="https://dragonlzm.github.io/zhuomingliu.github.io/images/Agile3D.png" style="width: 36%; margin-right: 20px;" />
    <div>
        <h2>Agile3D: Adaptive Contention- and Content-Aware 3D Object Detection for Embedded GPUs</h2>
        <p style="font-size: 15px; margin-bottom: -0.05em;">Under Review.</p>
        <p style="font-size: 15px; margin-bottom: -0.05em;">Pengcheng Wang, Zhuoming Liu, Shayok Bagchi, Ran Xu, Saurabh Bagchi, Yin Li, Somali Chaterji</p>
        <p style="font-size: 15px; "><a href="https://huggingface.co/papers/2412.03248">Paper</a> | <a href=" https://github.com/LaVi-Lab/AIM">Code</a> </p>
    </div>
</div> -->






<!-- Experience
======
1. **[2021.12-2023.05]** Research assistant at [USC IRIS computer vision Lab](https://sites.usc.edu/iris-cvlab/), supervised by Professor [Ram Nevatia](https://sites.usc.edu/iris-cvlab/professor-ram-nevatia/). 
1. **[2020.08-2021.07]** Research intern at [SenseTime Research](https://www.sensetime.com/en), supervised by Dr. [Conghui He](https://scholar.google.com/citations?user=PopTv7kAAAAJ&hl=en) and cooperated with Professor [Jifeng Dai](https://jifengdai.org/) -->

---

<h1 style=" margin-top: 2em; margin-bottom: -0.5em;">Experience</h1>
<ol>
    <li>
        <strong>[2024.05-Now]</strong> Research assistant at University of Wisconsin-Madison, advised by Professor 
        <a href="https://www.biostat.wisc.edu/~yli/">Yin Li</a>.
    </li>
    <li>
        <strong>[2021.12-2023.05]</strong> Applied Research Scientist at 
        <a href="https://amazon.jobs/content/en/teams/agi">Amazon AGI</a>, worked with Dr. 
        <a href="https://scholar.google.com/citations?user=2CkqEGcAAAAJ&hl=en">Robinson Piramuthu</a> and <a href="https://scholar.google.com/citations?user=AjTfCjEAAAAJ&hl=en">Xiaofeng Gao</a>.
    </li>
    <li>
        <strong>[2021.12-2023.05]</strong> Research assistant at 
        <a href="https://sites.usc.edu/iris-cvlab/">USC IRIS computer vision Lab</a>, advised by Professor 
        <a href="https://sites.usc.edu/iris-cvlab/professor-ram-nevatia/">Ram Nevatia</a>.
    </li>
    <li><strong>[2020.08-2021.07]</strong> Research intern at 
        <a href="https://www.sensetime.com/en">SenseTime Research</a>, worked with <a href="https://scholar.google.com/citations?user=AqmmngsAAAAJ&hl=en">Huaping Zhong</a>, Dr. 
        <a href="https://scholar.google.com/citations?user=PopTv7kAAAAJ&amp;hl=en">Conghui He</a> and Professor 
        <a href="https://jifengdai.org/">Jifeng Dai</a>.
    </li>
</ol>
